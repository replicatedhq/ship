{
  "v1": {
    "config": {},
    "releaseName": "concourse",
    "helmValuesDefaults": "## Default values for Concourse Helm Chart.\n## This is a YAML-formatted file.\n## Declare variables to be passed into your templates.\n\n## Override the name of the Chart.\n##\n# nameOverride:\n\n## Concourse image.\n##\nimage: concourse/concourse\n\n## Concourse image version.\n## ref: https://hub.docker.com/r/concourse/concourse/tags/\n##\nimageTag: \"4.2.2\"\n\n## Specific image digest to use in place of a tag.\n## ref: https://kubernetes.io/docs/concepts/configuration/overview/#container-images\n##\n# imageDigest: sha256:54ea351808b55ecc14af6590732932e2a6a0ed8f6d10f45e8be3b51165d5526a\n\n## Specify a imagePullPolicy: 'Always' if imageTag is 'latest', else set to 'IfNotPresent'.\n## ref: https://kubernetes.io/docs/user-guide/images/#pre-pulling-images\n##\nimagePullPolicy: IfNotPresent\n\n## Optionally specify an array of imagePullSecrets.\n## Secrets must be manually created in the namespace.\n## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/\n##\n# imagePullSecrets:\n#   - myRegistrKeySecretName\n\n## Configuration values for Concourse.\n## ref: https://concourse-ci.org/setting-up.html\n##\nconcourse:\n  web:\n    ## Minimum level of logs to see.\n    # logLevel: info\n    ## IP address on which to listen for web traffic.\n    # bindIp: 0.0.0.0\n    ## Port on which to listen for HTTP traffic.\n    bindPort: 8080\n    ## TLS configurations for the web component to be able to serve HTTPS traffic.\n    ## Once enabled, consumes the certificates set via secrets.\n    #\n    tls:\n      enabled: false\n      ## Port on which to listen for HTTPS traffic.\n      # bindPort:\n    ## URL used to reach any ATC from the outside world.\n    # externalUrl: http://127.0.0.1:8080\n    ## URL used to reach this ATC from other ATCs in the cluster.\n    # peerUrl: http://127.0.0.1:8080\n    ## Enable encryption of pipeline configuration. Encryption keys can be set via secrets.\n    ## See https://concourse-ci.org/encryption.html\n    ##\n    encryption:\n      enabled: false\n    localAuth:\n      enabled: true\n    ## IP address on which to listen for the pprof debugger endpoints.\n    # debugBindIp: 127.0.0.1\n    ## Port on which to listen for the pprof debugger endpoints.\n    # debugBindPort: 8079\n    ## Length of time for a intercepted session to be idle before terminating.\n    # interceptIdleTimeout: 0m\n    ## Time limit on checking for new versions of resources.\n    # globalResourceCheckTimeout: 1h\n    ## Interval on which to check for new versions of resources.\n    # resourceCheckingInterval: 1m\n    ## Interval on which to check for new versions of resource types.\n    # resourceTypeCheckingInterval: 1m\n    ## Method by which a worker is selected during container placement.\n    # containerPlacementStrategy: volume-locality\n    ## How long to wait for Baggageclaim to send the response header.\n    # baggageclaimResponseHeaderTimeout: 1m\n    ## Directory containing downloadable CLI binaries.\n    # cliArtifactsDir:\n    ## Log database queries.\n    # logDbQueries:\n    ## Interval on which to run build tracking.\n    # buildTrackerInterval: 10s\n    ## Default build logs to retain, 0 means all\n    # defaultBuildLogsToRetain:\n    ## Maximum build logs to retain, 0 means not specified. Will override values configured in jobs\n    # maxBuildLogsToRetain:\n    ## Default max number of cpu shares per task, 0 means unlimited\n    # defaultTaskCpuLimit:\n    ## Default maximum memory per task, 0 means unlimited\n    # defaultTaskMemoryLimit:\n    postgres:\n      ## The host to connect to.\n      host: 127.0.0.1\n      ## The port to connect to.\n      port: 5432\n      ## Path to a UNIX domain socket to connect to.\n      # socket:\n      ## Whether or not to use SSL.\n      sslmode: disable\n      ## Dialing timeout. (0 means wait indefinitely)\n      connectTimeout: 5m\n      ## The name of the database to use.\n      database: atc\n\n    kubernetes:\n\n      ## Enable the use of in-cluster Kubernetes Secrets.\n      ##\n      enabled: true\n\n      ## Prefix to use for Kubernetes namespaces under which secrets will be looked up. Defaults to\n      ## the Release name hyphen, e.g. \"my-release-\" produces namespace \"my-release-main\" for the\n      ## \"main\" Concourse team.\n      ##\n      ## namespacePrefix:\n\n      ## Teams to create namespaces for to hold secrets.\n      teams:\n        - main\n\n      ## Create the Kubernetes namespace for each team listed above.\n      createTeamNamespaces: true\n\n      ## When true, namespaces are not deleted when the release is deleted.\n      ## Irrelevant if the namespaces are not created by this chart.\n      keepNamespaces: true\n\n      ## Path to Kubernetes config when running ATC outside Kubernetes.\n      # configPath:\n\n    awsSecretsManager:\n      ## Enable the use of AWS Secrets Manager.\n      ##\n      enabled: false\n\n      ## AWS region to use when reading from Secrets Manager\n      ##\n      # region:\n\n      ## pipeline-specific template for Secrets Manager parameters, defaults to: /concourse/{team}/{pipeline}/{secret}\n      ##\n      # pipelineSecretTemplate:\n\n      ## team-specific template for Secrets Manager parameters, defaults to: /concourse/{team}/{secret}\n      ##\n      # teamSecretTemplate: ''\n\n    awsSsm:\n      ## Enable the use of AWS SSM.\n      ##\n      enabled: false\n\n      ## AWS region to use when reading from SSM\n      ##\n      # region:\n\n      ## pipeline-specific template for SSM parameters, defaults to: /concourse/{team}/{pipeline}/{secret}\n      ##\n      # pipelineSecretTemplate:\n\n      ## team-specific template for SSM parameters, defaults to: /concourse/{team}/{secret}\n      ##\n      # teamSecretTemplate: ''\n\n\n    vault:\n      enabled: false\n\n      ## URL pointing to vault addr (i.e. http://vault:8200).\n      ##\n      # url:\n\n      ## vault path under which to namespace credential lookup, defaults to /concourse.\n      ##\n      pathPrefix: /concourse\n\n      ## if the Vault server is using a self-signed certificate, set this to true,\n      ## and provide a value for the cert in secrets.\n      ##\n      # useCaCert:\n\n      ## vault authentication backend, leave this blank if using an initial periodic token\n      ## currently supported backends: token, approle, cert.\n      ##\n      # authBackend:\n\n      ## Cache returned secrets for their lease duration in memory\n      # cache:\n      ## If the cache is enabled, and this is set, override secrets lease duration with a maximum value\n      # maxLease:\n      ## Path to a directory of PEMEncoded CA cert files to verify the vault server SSL cert.\n      # caPath:\n      ## If set, is used to set the SNI host when connecting via TLS.\n      # serverName:\n      ## Enable insecure SSL verification.\n      # insecureSkipVerify:\n        ## Client token for accessing secrets within the Vault server.\n        # clientToken:\n      ## Auth backend to use for logging in to Vault.\n      # authBackend:\n      ## Time after which to force a reLogin. If not set, the token will just be continuously renewed.\n      # authBackendMaxTtl:\n      ## The maximum time between retries when logging in or reAuthing a secret.\n      retryMax: 5m\n      ## The initial time between retries when logging in or reAuthing a secret.\n      retryInitial: 1s\n    ## Don't actually do any automatic scheduling or checking.\n    # noop:\n    staticWorker:\n      enabled: false\n      ## A Garden API endpoint to register as a worker.\n      gardenUrl:\n      ## A Baggageclaim API endpoint to register with the worker.\n      baggageclaimUrl:\n      ## A resource type to advertise for the worker. Can be specified multiple times.\n      resource:\n    metrics:\n      ## Host string to attach to emitted metrics.\n      hostName:\n      ## A keyValue attribute to attach to emitted metrics. Can be specified multiple times.\n      attribute:\n    datadog:\n      enabled: false\n      ## Use IP of node the pod is scheduled on, overrides `agentHost`\n      agentHostUseHostIP: false\n      ## Datadog agent host to expose dogstatsd metrics\n      agentHost: 127.0.0.1\n      ## Datadog agent port to expose dogstatsd metrics\n      agentPort: 8125\n      ## Prefix for all metrics to easily find them in Datadog\n      # prefix: concoursedev\n    influxdb:\n      enabled: false\n      ## InfluxDB server address to emit points to.\n      url: http://127.0.0.1:8086\n      ## InfluxDB database to write points to.\n      database: concourse\n      ## InfluxDB server username.\n      # username:\n      ## Skip SSL verification when emitting to InfluxDB.\n      insecureSkipVerify: false\n    ## Emit metrics to logs.\n    # emitToLogs:\n    newrelic:\n      enabled: false\n      ## New Relic Account ID\n      # accountId:\n      ## New Relic Insights API Key\n      # apiKey:\n      ## An optional prefix for emitted New Relic events\n      # servicePrefix:\n    prometheus:\n      enabled: false\n      ## IP to listen on to expose Prometheus metrics.\n      bindIp: \"0.0.0.0\"\n      ## Port to listen on to expose Prometheus metrics.\n      bindPort: 9391\n    riemann:\n      enabled: false\n      ## Riemann server address to emit metrics to.\n      # host:\n      ## Port of the Riemann server to emit metrics to.\n      port: 5555\n      ## An optional prefix for emitted Riemann services\n      # servicePrefix:\n      ## Tag to attach to emitted metrics. Can be specified multiple times.\n      # tag:\n    ## The value to set for XFrame-Options. If omitted, the header is not set.\n    # xFrameOptions:\n    gc:\n      overrideDefaults: false\n      ## Interval on which to perform garbage collection.\n      interval: 30s\n      ## Grace period before reaping oneOff task containers\n      oneOffGracePeriod: 5m\n    syslog:\n      enabled: false\n      ## Client hostname with which the build logs will be sent to the syslog server.\n      hostName: atc-syslog-drainer\n      ## Remote syslog server address with port (Example: 0.0.0.0:514).\n      # address:\n      ## Transport protocol for syslog messages (Currently supporting tcp, udp \u0026 tls).\n      # transport:\n      ## Interval over which checking is done for new build logs to send to syslog server (duration measurement units are s/m/h; eg. 30s/30m/1h)\n      drainInterval: 30s\n      ## if the syslog server is using a self-signed certificate, set this to true,\n      ## and provide a value for the cert in secrets.\n      useCaCert: false\n    auth:\n      ## Force sending secure flag on http cookies\n      # cookieSecure:\n      ## Length of time for which tokens are valid. Afterwards, users will have to log back in.\n      # duration: 24h\n      mainTeam:\n        ## List of whitelisted local concourse users. These are the users you've added at atc startup with the addLocalUser setting.\n        localUser: \"test\"\n        ## Setting this flag will whitelist all logged in users in the system. ALL OF THEM. If, for example, you've configured GitHub, any user with a GitHub account will have access to your team.\n        # allowAllUsers:\n        ## Authentication (Main Team) (CloudFoundry)\n        cf:\n          ## List of whitelisted CloudFoundry users.\n          user:\n          ## List of whitelisted CloudFoundry orgs\n          org:\n          ## List of whitelisted CloudFoundry spaces\n          space:\n          ## (Deprecated) List of whitelisted CloudFoundry space guids\n          spaceGuid:\n        ## Authentication (Main Team) (GitHub)\n        github:\n          ## List of whitelisted GitHub users\n          user:\n          ## List of whitelisted GitHub orgs\n          org:\n          ## List of whitelisted GitHub teams\n          team:\n        ## Authentication (Main Team) (GitLab)\n        gitlab:\n          ## List of whitelisted GitLab users\n          user:\n          ## List of whitelisted GitLab groups\n          group:\n        ## Authentication (Main Team) (LDAP)\n        ldap:\n          ## List of whitelisted LDAP users\n          user:\n          ## List of whitelisted LDAP groups\n          group:\n        ## Authentication (Main Team) (OAuth2)\n        oauth:\n          ## List of whitelisted OAuth2 users\n          user:\n          ## List of whitelisted OAuth2 groups\n          group:\n        ## Authentication (Main Team) (OIDC)\n        oidc:\n          ## List of whitelisted OIDC users\n          user:\n          ## List of whitelisted OIDC groups\n          group:\n      ## Authentication (CloudFoundry)\n      cf:\n        enabled: false\n        ## (Required) The base API URL of your CF deployment. It will use this information to discover information about the authentication provider.\n        # apiUrl: https://api.run.pivotal.io\n        ## CA Certificate\n        # useCaCert:\n        ## Skip SSL validation\n        # skipSslValidation:\n      ## Authentication (GitHub)\n      github:\n        enabled: false\n        ## Hostname of GitHub Enterprise deployment (No scheme, No trailing slash)\n        # host:\n        ## CA certificate of GitHub Enterprise deployment\n        # useCaCert:\n      ## Authentication (GitLab)\n      gitlab:\n        enabled: false\n        ## Hostname of Gitlab Enterprise deployment (Include scheme, No trailing slash)\n        # host:\n      ## Authentication (LDAP)\n      ldap:\n        enabled: false\n        ## The auth provider name displayed to users on the login page\n        # displayName:\n        ## (Required) The host and optional port of the LDAP server. If port isn't supplied, it will be guessed based on the TLS configuration. 389 or 636.\n        # host:\n        ## (Required) Bind DN for searching LDAP users and groups. Typically this is a readOnly user.\n        # bindDn:\n        ## (Required) Bind Password for the user specified by 'bindDn'\n        # bindPw:\n        ## Required if LDAP host does not use TLS.\n        # insecureNoSsl:\n        ## Skip certificate verification\n        # insecureSkipVerify:\n        ## Start on insecure port, then negotiate TLS\n        # startTls:\n        ## CA certificate\n        # useCaCert:\n        ## BaseDN to start the search from. For example 'cn=users,dc=example,dc=com'\n        # userSearchBaseDn:\n        ## Optional filter to apply when searching the directory. For example '(objectClass=person)'\n        # userSearchFilter:\n        ## Attribute to match against the inputted username. This will be translated and combined with the other filter as '(\u003cattr\u003e=\u003cusername\u003e)'.\n        # userSearchUsername:\n        ## Can either be: 'sub'  search the whole sub tree or 'one' - only search one level. Defaults to 'sub'.\n        # userSearchScope:\n        ## A mapping of attributes on the user entry to claims. Defaults to 'uid'.\n        # userSearchIdAttr:\n        ## A mapping of attributes on the user entry to claims. Defaults to 'mail'.\n        # userSearchEmailAttr:\n        ## A mapping of attributes on the user entry to claims.\n        # userSearchNameAttr:\n        ## BaseDN to start the search from. For example 'cn=groups,dc=example,dc=com'\n        # groupSearchBaseDn:\n        ## Optional filter to apply when searching the directory. For example '(objectClass=posixGroup)'\n        # groupSearchFilter:\n        ## Can either be: 'sub'  search the whole sub tree or 'one' - only search one level. Defaults to 'sub'.\n        # groupSearchScope:\n        ## Adds an additional requirement to the filter that an attribute in the group match the user's attribute value. The exact filter being added is: (\u003cgroupAttr\u003e=\u003cuserAttr value\u003e)\n        # groupSearchUserAttr:\n        ## Adds an additional requirement to the filter that an attribute in the group match the user's attribute value. The exact filter being added is: (\u003cgroupAttr\u003e=\u003cuserAttr value\u003e)\n        # groupSearchGroupAttr:\n        ## The attribute of the group that represents its name.\n        # groupSearchNameAttr:\n      ## Authentication (OAuth2)\n      oauth:\n        enabled: false\n        ## The auth provider name displayed to users on the login page\n        # displayName:\n        ## (Required) Authorization URL\n        # authUrl:\n        ## (Required) Token URL\n        # tokenUrl:\n        ## UserInfo URL\n        # userinfoUrl:\n        ## Any additional scopes that need to be requested during authorization\n        # scope:\n        ## The groups key indicates which claim to use to map external groups to Concourse teams.\n        # groupsKey:\n        ## CA Certificate\n        # useCaCert:\n        ## Skip SSL validation\n        # skipSslValidation:\n      ## Authentication (OIDC)\n      oidc:\n        enabled: false\n        ## The auth provider name displayed to users on the login page\n        # displayName:\n        ## (Required) An OIDC issuer URL that will be used to discover provider configuration using the .wellKnown/openid-configuration\n        # issuer:\n        ## Any additional scopes that need to be requested during authorization\n        # scope:\n        ## The groups key indicates which claim to use to map external groups to Concourse teams.\n        # groupsKey:\n        ## CA Certificate\n        # useCaCert:\n        ## Skip SSL validation\n        # skipSslValidation:\n    tsa:\n      ## Minimum level of logs to see.\n      # logLevel: info\n      ## IP address on which to listen for SSH.\n      # bindIp: 0.0.0.0\n      ## Port on which to listen for SSH.\n      bindPort: 2222\n      ## Port on which to listen for TSA pprof server.\n      # bindDebugPort: 8089\n      ## IP address of this TSA, reachable by the ATCs. Used for forwarded worker addresses.\n      # peerIp:\n      ## Path to private key to use for the SSH server.\n      # hostKey:\n      ## Path to file containing keys to authorize, in SSH authorized_keys format (one public key per line).\n      # authorizedKeys:\n      ## Path to file containing keys to authorize, in SSH authorized_keys format (one public key per line).\n      # teamAuthorizedKeys:\n      ## ATC API endpoints to which workers will be registered.\n      # atcUrl:\n      ## Path to private key to use when signing tokens in reqests to the ATC during registration.\n      # sessionSigningKey:\n      ## interval on which to heartbeat workers to the ATC\n      # heartbeatInterval: 30s\n  worker:\n    ## The name to set for the worker during registration. If not specified, the hostname will be used.\n    # name:\n    ## A tag to set during registration. Can be specified multiple times.\n    # tag:\n    ## The name of the team that this worker will be assigned to.\n    # team:\n    ## HTTP proxy endpoint to use for containers.\n    # http_proxy:\n    ## HTTPS proxy endpoint to use for containers.\n    # https_proxy:\n    ## Blacklist of addresses to skip the proxy when reaching.\n    # no_proxy:\n    ## If set, the worker will be immediately removed upon stalling.\n    # ephemeral:\n    ## Port on which to listen for beacon pprof server.\n    # bindDebugPort: 9099\n    ## Version of the worker. This is normally baked in to the binary, so this flag is hidden.\n    # version:\n    ## Directory in which to place container data.\n    workDir: /concourse-work-dir\n    ## IP address on which to listen for the Garden server.\n    # bindIp: 127.0.0.1\n    ## Port on which to listen for the Garden server.\n    # bindPort: 7777\n    ## IP used to reach this worker from the ATC nodes.\n    # peerIp:\n    ## Minimum level of logs to see.\n    # logLevel: info\n    tsa:\n      ## TSA host to forward the worker through. Can be specified multiple times.\n      host: 127.0.0.1:2222\n      ## File containing a public key to expect from the TSA.\n      # publicKey:\n      ## File containing the private key to use when authenticating to the TSA.\n      # workerPrivateKey:\n    garden:\n      ## Minimum level of logs to see.\n      # logLevel: info\n      ## format of log timestamps\n      # timeFormat: unix-epoch\n      ## Bind with TCP on the given IP.\n      # bindIp:\n      ## Bind with TCP on the given port.\n      bindPort: 7777\n      ## Bind with Unix on the given socket path.\n      # bindSocket: /tmp/garden.sock\n      ## Bind the debug server on the given IP.\n      # debugBindIp:\n      ## Bind the debug server to the given port.\n      # debugBindPort: 17013\n      ## Skip the preparation part of the host that requires root privileges\n      # skipSetup:\n      ## Directory in which to store container data.\n      # depot: /var/run/gdn/depot\n      ## Path in which to store properties.\n      # propertiesPath:\n      ## Path in which to store temporary sockets\n      # consoleSocketsPath:\n      ## Clean up proccess dirs on first invocation of wait\n      # cleanupProcessDirsOnWait:\n      ## Disable creation of privileged containers\n      # disablePrivilegedContainers:\n      ## The lowest numerical subordinate user ID the user is allowed to map\n      # uidMapStart: 1\n      ## The number of numerical subordinate user IDs the user is allowed to map\n      # uidMapLength:\n      ## The lowest numerical subordinate group ID the user is allowed to map\n      # gidMapStart: 1\n      ## The number of numerical subordinate group IDs the user is allowed to map\n      # gidMapLength:\n      ## Default rootfs to use when not specified on container creation.\n      # defaultRootfs:\n      ## Default time after which idle containers should expire.\n      # defaultGraceTime:\n      ## Clean up all the existing containers on startup.\n      # destroyContainersOnStartup:\n      ## Apparmor profile to use for unprivileged container processes\n      # apparmor:\n      ## Directory in which to extract packaged assets\n      # assetsDir: /var/gdn/assets\n      ## Path to the 'dadoo' binary.\n      # dadooBin:\n      ## Path to the 'nstar' binary.\n      # nstarBin:\n      ## Path to the 'tar' binary.\n      # tarBin:\n      ## path to the iptables binary\n      # iptablesBin: /sbin/iptables\n      ## path to the iptables-restore binary\n      # iptablesRestoreBin: /sbin/iptables-restore\n      ## Path execute as pid 1 inside each container.\n      # initBin:\n      ## Path to the runtime plugin binary.\n      # runtimePlugin: runc\n      ## Extra argument to pass to the runtime plugin. Can be specified multiple times.\n      # runtimePluginExtraArg:\n      ## Directory on which to store imported rootfs graph data.\n      # graph:\n      ## Disk usage of the graph dir at which cleanup should trigger, or -1 to disable graph cleanup.\n      # graphCleanupThresholdInMegabytes: -1\n      ## Image that should never be garbage collected. Can be specified multiple times.\n      # persistentImage:\n      ## Path to image plugin binary.\n      # imagePlugin:\n      ## Extra argument to pass to the image plugin to create unprivileged images. Can be specified multiple times.\n      # imagePluginExtraArg:\n      ## Path to privileged image plugin binary.\n      # privilegedImagePlugin:\n      ## Extra argument to pass to the image plugin to create privileged images. Can be specified multiple times.\n      # privilegedImagePluginExtraArg:\n      ## Docker registry API endpoint.\n      # dockerRegistry: registry-1.docker.io\n      ## Docker registry to allow connecting to even if not secure. Can be specified multiple times.\n      # insecureDockerRegistry:\n      ## Network range to use for dynamically allocated container subnets.\n      # networkPool: 10.254.0.0/22\n      ## Allow network access to the host machine.\n      # allowHostAccess:\n      ## Network ranges to which traffic from containers will be denied. Can be specified multiple times.\n      # denyNetwork:\n      ## DNS server IP address to use instead of automatically determined servers. Can be specified multiple times.\n      # dnsServer:\n      ## DNS server IP address to append to the automatically determined servers. Can be specified multiple times.\n      # additionalDnsServer:\n      ## Per line hosts entries. Can be specified multiple times and will be appended verbatim in order to /etc/hosts\n      # additionalHostEntry:\n      ## IP address to use to reach container's mapped ports. Autodetected if not specified.\n      # externalIp:\n      ## Start of the ephemeral port range used for mapped container ports.\n      # portPoolStart: 61001\n      ## Size of the port pool used for mapped container ports.\n      # portPoolSize: 4534\n      ## Path in which to store port pool properties.\n      # portPoolPropertiesPath:\n      ## MTU size for container network interfaces. Defaults to the MTU of the interface used for outbound access by the host. Max allowed value is 1500.\n      # mtu:\n      ## Path to network plugin binary.\n      # networkPlugin:\n      ## Extra argument to pass to the network plugin. Can be specified multiple times.\n      # networkPluginExtraArg:\n      ## Maximum number of microseconds each cpu share assigned to a container allows per quota period\n      # cpuQuotaPerShare: 0\n      ## Set hard limit for the tcp buf memory, value in bytes\n      # tcpMemoryLimit: 0\n      ## Default block IO weight assigned to a container\n      # defaultContainerBlockioWeight: 0\n      ## Maximum number of containers that can be created.\n      # maxContainers: 0\n      ## Disable swap memory limit\n      # disableSwapLimit:\n      ## Interval on which to emit metrics.\n      # metricsEmissionInterval: 1m\n      ## Origin identifier for Dropsonde-emitted metrics.\n      # dropsondeOrigin: garden-linux\n      ## Destination for Dropsonde-emitted metrics.\n      # dropsondeDestination: 127.0.0.1:3457\n      ## Path to a containerd socket.\n      # containerdSocket:\n      ## Use containerd to run processes in containers.\n      # useContainerdForProcesses:\n      ## Enable proxy DNS server.\n      # dnsProxyEnable:\n    baggageclaim:\n      ## Minimum level of logs to see.\n      # logLevel: info\n      ## IP address on which to listen for API traffic.\n      # bindIp: 127.0.0.1\n      ## Port on which to listen for API traffic.\n      # bindPort: 7788\n      ## Port on which to listen for baggageclaim pprof server.\n      # bindDebugPort: 8099\n      ## Directory in which to place volume data.\n      # volumes:\n      ## Driver to use for managing volumes.\n      driver: naive\n      ## Path to btrfs binary\n      # btrfsBin: btrfs\n      ## Path to mkfs.btrfs binary\n      # mkfsBin: mkfs.btrfs\n      ## Path to directory in which to store overlay data\n      # overlaysDir:\n      ## Interval on which to reap expired volumes.\n      # reapInterval: 10s\n\n## Configuration values for Concourse Web components.\n##\nweb:\n  ## Override the components name (defaults to web).\n  ##\n  # nameOverride:\n\n  ## Number of replicas.\n  ##\n  replicas: 1\n\n  ## Configures the liveness probe used to determine\n  ## if the Web component is up.\n  ## Note.: if you're upgrading Concourse from one version\n  ## to another, the probe will probably fail for some time\n  ## before migrations are finished - in such situations,\n  ## either consider bumping the values set here.\n  livenessProbe:\n    failureThreshold: 5\n    httpGet:\n      path: /api/v1/info\n      port: atc\n    initialDelaySeconds: 10\n    periodSeconds: 15\n    timeoutSeconds: 3\n\n  ## Configures the readiness probes.\n  readinessProbe:\n    httpGet:\n      path: /api/v1/info\n      port: atc\n\n  ## Configure resource requests and limits.\n  ## ref: https://kubernetes.io/docs/user-guide/compute-resources/\n  ##\n  resources:\n    requests:\n      cpu: \"100m\"\n      memory: \"128Mi\"\n\n  ## Configure additional environment variables for the\n  ## web containers.\n  # env:\n  #   - name: CONCOURSE_LOG_LEVEL\n  #     value: \"debug\"\n  #   - name: CONCOURSE_TSA_LOG_LEVEL\n  #     value: \"debug\"\n\n  ## For managing where secrets should be mounted for the web agents\n  keySecretsPath: \"/concourse-keys\"\n  authSecretsPath: \"/concourse-auth\"\n  vaultSecretsPath: \"/concourse-vault\"\n  postgresqlSecretsPath: \"/concourse-postgresql\"\n  syslogSecretsPath: \"/concourse-syslog\"\n  tlsSecretsPath: \"/concourse-web-tls\"\n\n  ## Configure additional volumes for the\n  ## web container(s)\n  ##\n  # additionalVolumes:\n  #   - name: my-team-authorized-keys\n  #     configMap:\n  #       name: my-team-authorized-keys-config\n\n  ## Configure additional volumeMounts for the\n  ## web container(s)\n  ##\n  # additionalVolumeMounts:\n  #   - name: my-team-authorized-keys\n  #     mountPath: /my-team-authorized-keys\n\n  ## Additional affinities to add to the web pods.\n  ##\n  # additionalAffinities:\n  #   nodeAffinity:\n  #     preferredDuringSchedulingIgnoredDuringExecution:\n  #       - weight: 50\n  #         preference:\n  #           matchExpressions:\n  #             - key: spot\n  #               operator: NotIn\n  #               values:\n  #                 - \"true\"\n\n  ## Annotations for the web nodes.\n  ## Ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/\n  annotations: {}\n  # annotations:\n  #   key1: \"value1\"\n  #   key2: \"value2\"\n\n  ## Node selector for web nodes.\n  nodeSelector: {}\n\n  ## Tolerations for the web nodes.\n  ## Ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/\n  tolerations: []\n  # tolerations:\n  #  - key: \"toleration=key\"\n  #    operator: \"Equal\"\n  #    value: \"value\"\n  #    effect: \"NoSchedule\"\n\n  ## Service configuration.\n  ## ref: https://kubernetes.io/docs/user-guide/services/\n  ##\n  service:\n    ## For minikube, set this to ClusterIP, elsewhere use LoadBalancer or NodePort\n    ## ref: https://kubernetes.io/docs/user-guide/services/#publishing-services---service-types\n    ##\n    type: ClusterIP\n\n    ## When using web.service.type: LoadBalancer, sets the user-specified load balancer IP\n    # loadBalancerIP: 172.217.1.174\n\n    # # Additional Labels to be added to the web service.\n    # labels:\n\n    ## Annotations to be added to the web service.\n    ##\n    # annotations:\n    #   prometheus.io/probe: \"true\"\n    #   prometheus.io/probe_path: \"/\"\n    #\n    #   ## When using web.service.type: LoadBalancer, enable HTTPS with an ACM cert\n    #   service.beta.kubernetes.io/aws-load-balancer-ssl-cert: \"arn:aws:acm:eu-west-1:123456789:certificate/abc123-abc123-abc123-abc123\"\n    #   service.beta.kubernetes.io/aws-load-balancer-backend-protocol: \"http\"\n    #   service.beta.kubernetes.io/aws-load-balancer-backend-port: \"atc\"\n    #   service.beta.kubernetes.io/aws-load-balancer-ssl-ports: \"443\"\n    #\n    # ## When using web.service.type: LoadBalancer, whitelist the load balancer to particular IPs\n    # loadBalancerSourceRanges:\n    #   - 192.168.1.10/32\n\n  # When using web.service.type: NodePort, sets the nodePort for atc\n  #  atcNodePort: 30150\n  #\n  # When using web.service.type: NodePort, sets the nodePort for atc tls\n  #  atcTlsNodePort: 30151\n  #\n  # When using web.service.type: NodePort, sets the nodePort for tsa\n  #  tsaNodePort: 30152\n\n  ## Ingress configuration.\n  ## ref: https://kubernetes.io/docs/user-guide/ingress/\n  ##\n  ingress:\n    ## Enable Ingress.\n    ##\n    enabled: false\n\n    ## Annotations to be added to the web ingress.\n    ##\n    # annotations:\n    #   kubernetes.io/ingress.class: nginx\n    #   kubernetes.io/tls-acme: 'true'\n\n    ## Hostnames.\n    ## Must be provided if Ingress is enabled.\n    ##\n    # hosts:\n    #   - concourse.domain.com\n\n    ## TLS configuration.\n    ## Secrets must be manually created in the namespace.\n    ##\n    # tls:\n    #   - secretName: concourse-web-tls\n    #     hosts:\n    #       - concourse.domain.com\n    #\n    #\n\n## Configuration values for Concourse Worker components.\n##\nworker:\n  ## Override the components name (defaults to worker).\n  ##\n  # nameOverride:\n\n  ## Number of replicas.\n  ##\n  replicas: 2\n\n  ## Minimum number of workers available after an eviction\n  ## ref: https://kubernetes.io/docs/admin/disruptions/\n  ##\n  minAvailable: 1\n\n  ## Configure resource requests and limits.\n  ## ref: https://kubernetes.io/docs/user-guide/compute-resources/\n  ##\n  resources:\n    requests:\n      cpu: \"100m\"\n      memory: \"512Mi\"\n\n  ## Configure additional environment variables for the\n  ## worker container(s)\n  # env:\n  #   - name: http_proxy\n  #     value: \"http://proxy.your-domain.com:3128\"\n  #   - name: https_proxy\n  #     value: \"http://proxy.your-domain.com:3128\"\n  #   - name: no_proxy\n  #     value: \"your-domain.com\"\n  #   - name: CONCOURSE_GARDEN_DNS_SERVER\n  #     value: \"8.8.8.8\"\n  #   - name: CONCOURSE_GARDEN_DNS_PROXY_ENABLE\n  #     value: \"true\"\n  #   - name: CONCOURSE_GARDEN_ALLOW_HOST_ACCESS\n  #     value: \"true\"\n\n\n  ## For managing where secrets should be mounted for worker agents\n  keySecretsPath: \"/concourse-keys\"\n\n  ## Configure additional volumeMounts for the\n  ## worker container(s)\n  # additionalVolumeMounts:\n  #   - name: concourse-baggageclaim\n  #     mountPath: /baggageclaim\n\n  ## Annotations to be added to the worker pods.\n  ##\n  # annotations:\n  #   iam.amazonaws.com/role: arn:aws:iam::123456789012:role/concourse\n  #\n\n  ## Node selector for the worker nodes.\n  ## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#nodeselector\n  nodeSelector: {}\n  # nodeSelector: {type: concourse}\n\n  ## Additional affinities to add to the worker pods.\n  ## Useful if you prefer to run workers on non-spot instances, for example\n  ##\n  # additionalAffinities:\n  #   nodeAffinity:\n  #     preferredDuringSchedulingIgnoredDuringExecution:\n  #       - weight: 50\n  #         preference:\n  #           matchExpressions:\n  #             - key: spot\n  #               operator: NotIn\n  #               values:\n  #                 - \"true\"\n\n  ## Configure additional volumes for the\n  ## worker container(s)\n  # additionalVolumes:\n  #   - name: concourse-baggageclaim\n  #     hostPath:\n  #       path: /dev/nvme0n1\n  #       type: BlockDevice\n  #\n  # As a special exception, this allows taking over the `concourse-work-dir`\n  # volume (from the default emptyDir) if `persistence.enabled` is false:\n  #\n  # additionalVolumes:\n  #   - name: concourse-work-dir\n  #     hostPath:\n  #       path: /mnt/locally-mounted-fast-disk/concourse\n  #       type: DirectoryOrCreate\n\n  ## Whether the workers should be forced to run on separate nodes.\n  ## This is accomplished by setting their AntiAffinity with requiredDuringSchedulingIgnoredDuringExecution as opposed to preferred\n  ## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#inter-pod-affinity-and-anti-affinity-beta-feature\n  hardAntiAffinity: false\n\n  ## Tolerations for the worker nodes.\n  ## Ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/\n  tolerations: []\n  # tolerations:\n  #  - key: \"toleration=key\"\n  #    operator: \"Equal\"\n  #    value: \"value\"\n  #    effect: \"NoSchedule\"\n\n  ## Time to allow the pod to terminate before being forcefully terminated. This should provide time for\n  ## the worker to retire, i.e. drain its tasks. See https://concourse-ci.org/worker-internals.html for worker\n  ## lifecycle semantics.\n  terminationGracePeriodSeconds: 60\n\n  ## If any of the strings are found in logs, the worker's livenessProbe will fail and trigger a pod restart.\n  ## Specify one string per line, exact matching is used.\n  ##\n  fatalErrors: |-\n    guardian.api.garden-server.create.failed\n    baggageclaim.api.volume-server.create-volume-async.failed-to-create\n\n  ## Strategy for StatefulSet updates (requires Kubernetes 1.6+)\n  ## Ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset\n  ##\n  updateStrategy: RollingUpdate\n\n  ## Pod Management strategy (requires Kubernetes 1.7+)\n  ## Ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#pod-management-policies\n  ##\n  ## \"OrderedReady\" is default. \"Parallel\" means worker pods will launch or terminate\n  ## in parallel.\n  podManagementPolicy: Parallel\n\n  ## When persistance is disabled this value will be used to limit the emptyDir volume size\n  ## Ref: https://kubernetes.io/docs/concepts/storage/volumes/#emptydir\n  # emptyDirSize: 20Gi\n\n## Persistent Volume Storage configuration.\n## ref: https://kubernetes.io/docs/user-guide/persistent-volumes\n##\npersistence:\n  ## Enable persistence using Persistent Volume Claims.\n  ##\n  enabled: true\n\n  ## Worker Persistence configuration.\n  ##\n  worker:\n    ## concourse data Persistent Volume Storage Class\n    ## If defined, storageClassName: \u003cstorageClass\u003e\n    ## If set to \"-\", storageClassName: \"\", which disables dynamic provisioning\n    ## If undefined (the default) or set to null, no storageClassName spec is\n    ##   set, choosing the default provisioner.  (gp2 on AWS, standard on\n    ##   GKE, AWS \u0026 OpenStack)\n    ##\n    # storageClass: \"-\"\n\n    ## Persistent Volume Access Mode.\n    ##\n    accessMode: ReadWriteOnce\n\n    ## Persistent Volume Storage Size.\n    ##\n    size: 20Gi\n\n## Configuration values for the postgresql dependency.\n## ref: https://github.com/kubernetes/charts/blob/master/stable/postgresql/README.md\n##\npostgresql:\n\n  ## Use the PostgreSQL chart dependency.\n  ## Set to false if bringing your own PostgreSQL, and set secret value postgresql-uri.\n  ##\n  enabled: true\n\n  ### PostgreSQL User to create.\n  ##\n  postgresUser: concourse\n\n  ## PostgreSQL Password for the new user.\n  ## If not set, a random 10 characters password will be used.\n  ##\n  postgresPassword: concourse\n\n  ## PostgreSQL Database to create.\n  ##\n  postgresDatabase: concourse\n\n  ## Persistent Volume Storage configuration.\n  ## ref: https://kubernetes.io/docs/user-guide/persistent-volumes\n  ##\n  persistence:\n    ## Enable PostgreSQL persistence using Persistent Volume Claims.\n    ##\n    enabled: true\n    ## concourse data Persistent Volume Storage Class\n    ## If defined, storageClassName: \u003cstorageClass\u003e\n    ## If set to \"-\", storageClassName: \"\", which disables dynamic provisioning\n    ## If undefined (the default) or set to null, no storageClassName spec is\n    ##   set, choosing the default provisioner.  (gp2 on AWS, standard on\n    ##   GKE, AWS \u0026 OpenStack)\n    ##\n    # storageClass: \"-\"\n    ## Persistent Volume Access Mode.\n    ##\n    accessMode: ReadWriteOnce\n    ## Persistent Volume Storage Size.\n    ##\n    size: 8Gi\n\n## For RBAC support:\nrbac:\n  # true here enables creation of rbac resources\n  create: true\n\n  # rbac version\n  apiVersion: v1beta1\n\n  ## The name of the service account to use for web pods if rbac.create is false\n  ##\n  webServiceAccountName: default\n\n  ## The name of the service account to use for worker pods if rbac.create is false\n  ##\n  workerServiceAccountName: default\n\n## For managing secrets using Helm\n##\nsecrets:\n\n  ## List of username:password or username:bcrypted_password combinations for all your local concourse users.\n  localUsers: \"test:test\"\n  ## Create the secret resource from the following values. Set this to\n  ## false to manage these secrets outside Helm.\n  ##\n  create: true\n\n  ## The TLS certificate and private key for the web component to be able to terminate\n  ## TLS connections.\n  # webTlsCert:\n  # webTlsKey:\n\n  ## Concourse Host Keys.\n  ## ref: https://concourse-ci.org/install.html#generating-keys\n  ##\n  hostKey: |-\n    -----BEGIN RSA PRIVATE KEY-----\n    MIIEogIBAAKCAQEA2AUPXxuiDC/qrBWjIdT5fvNcMlMEYpR3X4SLQIgLC1ULDsCO\n    fleKZ+Wi4RzwbkUKiKmJm5GeyNVVCDdfvdD1Sd1+5faqmp2/OQBzLS7o8NY/btMw\n    8h9lx4KVJaJJ1EM1EiyGY41Nx591KP14pBfr0/NdOIrDu2JvF6e7CHEbrzkN57kb\n    BVQkaIMaS01Rw/5Oe68GFalli2ii8L8dNWVVzquBh5PwVWimvTgwv3TYG2TH8L1V\n    V7n+/zRRpkjMl2+PUouGqD+Bp+4wF+hp4AW5v24CqjtLJEMv4IEJv2FRfrOauBIZ\n    XjAS1SSg9VaTOS3iwxaYrv8uG1XfMFHICvkEPQIDAQABAoIBAG87W8jrX6vK2Jm3\n    ooJ/OeFmymiXWsCwFi+2/kVCR/2T0tfLyxO/W+NX2WD1F9CP+HaaZeMXPp3HS7up\n    V8FT4ZohVYBwXTS0WYyucKApcYThrVQRpzhldnEfClGQmVeVK7Sp/KEyV4Sc1SVA\n    L2i/cI142N2Ohm7spquVkLcuFsVINzZ0fXCv25dTqbkEgjTJzNdBzyFXvc4z0Mt9\n    gW14M7mz+YKYOfsCxIEm438fC9b16C96yIFBdN+/jaP8pmb2RoIE2D0F8bj5K1hR\n    YyGFKMOU4e6cYq59iWfubKuu2WNJEBk/5aO7x7Xu2S0k8wIYlwxFuu4LfR2Kvizu\n    +mFVf3kCgYEA9e0+40tJGpOPM8hAB3DwXjYc8lCuyYf3z30T3RqVNCUVSWnlaj/s\n    3ENi6+Ng3u+Zs8cR2CFou+jAClTyWLuSnI9yACD0eyW9n4bzYMUbgdC6vneLjpzx\n    wWR9Xv5RmZVly7xWuqcgEeEf8RNcYI3oXby0laF3EObvuAx/4ETIkFcCgYEA4N42\n    w1UEWGopWBIIXYHkEPHQuF0SxR2CZyh9ExTeSxFphyibkcHRjDW+t91ZLnSm5k1N\n    TOdYuc0ApBV3U+TexeFvDI94L/Oze6Ht5MatRQz8kRwMFGJL3TrpbgTmWdfG05Ad\n    oiScJzwY16oJXnKusxik7V+gCCNNE0/2UuMnY4sCgYAEf82pvOPef5qcGOrK+A79\n    ukG3UTCRcVJgUmp9nhHivVbxW+WdlwPPV9BEfol0KrAGMPsrmBjhbzWsOregVfYt\n    tRYh2HiAlEUu2Po06AZDzrzL5UYBWu+1WRBOH5sAk1IkcxKnIY2dph++elszTQVW\n    SbCIGEckYQU7ucbRJJECywKBgBb4vHFx8vKxTa3wkagzx7+vZFohL/SxEgxFx5k2\n    bYsPqU8kZ9gZC7YeG3CfDShAxHgMd5QeoiLA/YrFop4QaG2gnP6UfXuwkqpTnYDc\n    hwDh1b9hNR6z9/oOtaAGoh2VfHtKYqyYvtcHPaZyeWiLoKstHlQdi7SpHouVhJ1t\n    FS4HAoGAGy+56+zvdROjJy9A2Mn/4BvWrsu4RSQILBJ6Hb4TpF46p2fn0rwqyhOj\n    Occs+xkdEsI9w5phXzIEeOq2LqvWHDPxtdLpxOrrmx4AftAWdM8S1+OqTpzHihK1\n    y1ZOrWfvON+XjWFFAEej/CpQZkNUkTzjTtSC0dnfAveZlasQHdI=\n    -----END RSA PRIVATE KEY-----\n\n  hostKeyPub: |-\n    ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDYBQ9fG6IML+qsFaMh1Pl+81wyUwRilHdfhItAiAsLVQsOwI5+V4pn5aLhHPBuRQqIqYmbkZ7I1VUIN1+90PVJ3X7l9qqanb85AHMtLujw1j9u0zDyH2XHgpUloknUQzUSLIZjjU3Hn3Uo/XikF+vT8104isO7Ym8Xp7sIcRuvOQ3nuRsFVCRogxpLTVHD/k57rwYVqWWLaKLwvx01ZVXOq4GHk/BVaKa9ODC/dNgbZMfwvVVXuf7/NFGmSMyXb49Si4aoP4Gn7jAX6GngBbm/bgKqO0skQy/ggQm/YVF+s5q4EhleMBLVJKD1VpM5LeLDFpiu/y4bVd8wUcgK+QQ9 Concourse\n\n  ## Concourse Session Signing Keys.\n  ## ref: https://concourse-ci.org/install.html#generating-keys\n  ##\n  sessionSigningKey: |-\n    -----BEGIN RSA PRIVATE KEY-----\n    MIIEowIBAAKCAQEAwLql/rUIaI+PX7Tl3FWcTee4sQf8/daakALXx955tPwkhqlY\n    e4T2V84p/ylFvNWpM4vfcMYKfMY0JLKgAgBvJhCytSkDBhTBoWmN6yE0AB11P9En\n    lIZRBWNYqaC2cSge2ZD8qOSnwfFhnQAW8+7pE+ElJAVh7dtdF3A478H50lIigq8I\n    zMWp2EGJpFC7/Uu36oIL/03MNGCmrH1jvtTuJiAMQUZYyL1ReBkvvHOzw9i4HXPy\n    SMVtcllm4NBs2aVPtwhr2kwSkLt8t1bPdRn6OIyEAw5WktzAKaiZnkTvj6g3xzdp\n    zKcrdlBr9aznlNvoSinBUfvtwyFmvFN1HHbA9wIDAQABAoIBAE7G/DrUfI9gvtX7\n    90jMpYsigFe8UCjho2PiBZlo0o6r0bJJXiV+/8J8PqZRlHPPUc4EClzqVjcSPRYS\n    /VxUGRqSELoD/Xxq14rGvn+xnrO9VsOzFl6bWFq/dOpBCtHN+G4t2VifvgKES8YE\n    11z19sdta+UBXjn/RFnkQSGfRCI3QqTaYvjxevt0uWlyPmqkFPQQw8bvHIXzoB+B\n    rzeiMa++nMvbX5pAH9XA0BvhyuH3fHidTUwiVBpkMcpLWtjP0A0JTsecDdbinDDq\n    un2EIo8zMWRwKQN/JnUxsi8AUEigBTCUqeDgREXtW62uvFkSpcVMXwmVityLYIVy\n    qnVLUCECgYEA6IwXkP1qnSfcNeoVI/ypDuz1/kdqcjSPhLYe+jdiLLoFkMW9AlDm\n    lzwNaWlTFD9ygo+NjJCo63/A8HCm55sajws5hZ6r20vdZcKFMk9h0qF5oVA7lkQ2\n    gvG2WaznuU7KkqhfP+pXhiLgZKoJkst/+g7r6uHpredwDY6hxeBK4vsCgYEA1CqH\n    8ywC5qUo/36kQg/TU2adN/YEHdJAAbU23EVrGQSVmnXW08H2NLFk0tsxrwoNnbgp\n    PIk2J7BimbJvbND17ibr4GAklDTsR8aJkDl+0JgNCAK9N07qVt1s7FXzhg95jUL9\n    EQW55z60GAJpecqNwA4Jsa8P852N0355Obp92TUCgYBkOBvf7JcJ66fHxH4f6D+j\n    oxPQ5k5Fsck4VJS9GSlCRVkor09ptBvsiYDuMOoRC9b51YwXTDDAbWplNOd5YSrt\n    AtVjdKJz/BoKRO7KY9Owxs54au+DLxqfDDSeKRokjoRW+CE0lnXp5RX3zCAcF3+r\n    8MpTi9D9lYSBEzs84BDmCQKBgQCMcH6/K3HcJJVn0fd+tyUGftUw9sswxjySJNbk\n    pZrH263/qWMDls+Xf5kire9MU1ZCAWZiaN0NFoed/2wcVpGEDAV0548u/30r4bKr\n    YjOcdhmiJNYFJ1qdF0MDib2CDvpB1IbZXrX46RujDO2urbJ435HxKNVhR/had8xc\n    tyKYxQKBgCVDhN0MhnlUQJVZfX42APmF4gQg0r3sfL/NGXjEjMIKKFe5a88eZVHr\n    L8x1+dp0q7czC8a/l1DUuiwDKl8OEpxLsGCq/J/wAfrSMPifu6EUlbUwlJOPdgha\n    +p/KFAelHXJ2w/8yackAcarh35VP7ixhuvxswHNdgvfsBTFcjn30\n    -----END RSA PRIVATE KEY-----\n\n  ## Concourse Worker Keys.\n  ## ref: https://concourse-ci.org/install.html#generating-keys\n  ##\n  workerKey: |-\n    -----BEGIN RSA PRIVATE KEY-----\n    MIIEpAIBAAKCAQEAuPehUmBXAQCoA7TLAQCYhf+vzcZVyj+VGXnMhLHnWLk7dRjo\n    CU8GgNamdS5h7G3ywxOvKA3YjOLr8XyOMLS4c+e8N7tIzlMWdiXhe0lcBH9Z1ai5\n    +Bof3/BlDUBksiKdc1A+QcfX6tDwMkOO5re1H4vOK3H/Cype58wCB03HYNgb05ED\n    fW1Bj2qvz29VtmyjwEMuDs100iMqwCfPUx9oxXmmX8sUBRmw/Y1Rx/8pdKIjKw3m\n    kWIHHBOSCPimO1qC47Aa8v/UH9hERCykyuFHiBiKlnIvZWm9bYvhsRTz4gt5KzRY\n    6OI0oVeHlLOHDSK48Da8VWij15lOqO2Nx6WssQIDAQABAoIBADET22UNFOi6MNpS\n    5S5N5ypezlnOD0NLnZcV3zMyNQ0wkNsgEakuo64Zxi7/cJIYFjq2hVoeWl//cdUw\n    VFYODYcLbMBo3AeKukH9CRf6PgUfeUmcrENtQxnbIiTi+hTd5GMNXod7rAmtCJ59\n    mHQVOGS3ZqvWYnKm+mmMktk3RPinynX/A4y3WHPacuAS58HM09Ck43WcHMxbGpsL\n    /gZpICyFYZ2DviM+AHyWGcmw7LJrpC0QHo6+BAFMs4xlUecNgVIFUpfOoAcfsdtG\n    K9j4AbuZ47iFisbay+1pyg/7O5eRTdGVQRtc7PBMOjea5jGsfmlDmdn1ZS50ykun\n    ANfoQ5UCgYEA9Ak73PRy9nLlRkt4OBCF/4fwThUCMedsnWaVjQBMJYim4FB2ivF5\n    cKdWt3y/RZI85KKYu0EXhLEoSIEAfz057R8t3QdVK4tZx6B47UFjBjCYeVMtwHDQ\n    prxQiOPHIHCplBNFuGzA5VXL9gQLRD+ek0uOy2GJJ0Wu1xyeouI+SW8CgYEAwgkO\n    TOtOogqmcAALjWgeeQiZetflSKbJlpQNhmCPAMm0SFI8eF4SpRXLzd41VC2mLIwT\n    L3tjc7/8ocXoElFM4L0fo9Lx/SHFH4JEn5FT0PXPmvsF2JRhsXJFLJSihxF/91Xs\n    2aBcQILPFzLcrI6OFUakNwGTU/CIxpkzRvQrG98CgYEAzNVnUuo4CNadzagRK3Xr\n    E3Yl5VRK+FpY17FAfA6w25xc/dFr/un61e0Po4no/ltmEz7LVfmn5O/ScTEemq5o\n    jbjrBShfe+JGpIH0nqiQlqR5hvSjZXEMIbfVHWGbRYZrQGgA0HEwZA7k2QXB8zI3\n    R0lXfSzMM5OQ0uwp12xxfa8CgYBHILq1R6zTicPpWprhg0FobNaWSX4rW7iaEjvC\n    /rJtP4Nu33Z7SUDcc1j6ZnJ2ISXBPrfpt/mE/OPHCZ1A2bysxadLjpBWkoKIQmCV\n    fdiTyQgJb+t8sSf+vDzPUs0hZjDaogzo2ff3TfxMLMDoIHnFItgfsdwn8QyygIZj\n    hC4pUQKBgQDqsxnkI6yXFE5gshnW7H8zqKNlzKd/dZEL6e+lRz4R3UY/KcEkRAfq\n    Yi3cwo9fE3U3kSmpl5MQwUjWm/BZ7JyueoY/4ndwaFPgc34IKsgJ0wau9pZiQAB1\n    DxpOSF+BR71Jx3sxvIdCODNTtm645j5yrZVnJAuMPofo5XFmunDoJA==\n    -----END RSA PRIVATE KEY-----\n\n  workerKeyPub: |-\n    ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQC496FSYFcBAKgDtMsBAJiF/6/NxlXKP5UZecyEsedYuTt1GOgJTwaA1qZ1LmHsbfLDE68oDdiM4uvxfI4wtLhz57w3u0jOUxZ2JeF7SVwEf1nVqLn4Gh/f8GUNQGSyIp1zUD5Bx9fq0PAyQ47mt7Ufi84rcf8LKl7nzAIHTcdg2BvTkQN9bUGPaq/Pb1W2bKPAQy4OzXTSIyrAJ89TH2jFeaZfyxQFGbD9jVHH/yl0oiMrDeaRYgccE5II+KY7WoLjsBry/9Qf2ERELKTK4UeIGIqWci9lab1ti+GxFPPiC3krNFjo4jShV4eUs4cNIrjwNrxVaKPXmU6o7Y3Hpayx Concourse\n\n  ## Secrets for DB access\n  # postgresUser:\n  # postgresPassword:\n  # postgresCaCert:\n  # postgresClientCert:\n  # postgresClientKey:\n\n  ## Secrets for DB encryption\n  ##\n  # encryptionKey:\n  # oldEncryptionKey:\n\n  ## Secrets for SSM AWS access\n  # awsSsmAccessKey:\n  # awsSsmSecretKey:\n  # awsSsmSessionToken:\n\n  ## Secrets for Secrets Manager AWS access\n  # awsSecretsmanagerAccessKey:\n  # awsSecretsmanagerSecretKey:\n  # awsSecretsmanagerSessionToken:\n\n  ## Secrets for CF OAuth\n  # cfClientId:\n  # cfClientSecret:\n  # cfCaCert: |-\n\n  ## Secrets for GitHub OAuth.\n  ##\n  # githubClientId:\n  # githubClientSecret:\n  # githubCaCert: |-\n\n  ## Secrets for GitLab OAuth.\n  ##\n  # gitlabClientId:\n  # gitlabClientSecret:\n\n  ## Secrets for LDAP Auth.\n  ##\n  # ldapCaCert: |-\n\n  ## Secrets for generic OAuth.\n  ##\n  # oauthClientId:\n  # oauthClientSecret:\n  # oauthCaCert: |-\n\n  ## Secrets for oidc OAuth.\n  ##\n  # oidcClientId:\n  # oidcClientSecret:\n  # oidcCaCert: |-\n\n  ## Secrets for using Hashcorp Vault as a credential manager.\n  ##\n  ## if the Vault server is using a self-signed certificate, provide the CA public key.\n  ## the value will be written to /concourse-vault/ca.cert\n  ##\n  # vaultCaCert: |-\n\n  ## initial periodic token issued for concourse\n  ## ref: https://www.vaultproject.io/docs/concepts/tokens.html#periodic-tokens\n  ##\n  # vaultClientToken:\n\n  ## vault authentication parameters\n  ## Paramter to pass when logging in via the backend\n  ## Required for \"approle\" authenication method\n  ## e.g. \"role_id=x,secret_id=x\"\n  ## ref: https://concourse-ci.org/creds.html#vault-auth-param=NAME=VALUE\n  ##\n  # vaultAuthParam:\n\n  ## provide the client certificate for authenticating with the [TLS](https://www.vaultproject.io/docs/auth/cert.html) backend\n  ## the value will be written to /concourse-vault/client.cert\n  ## make sure to also set credentialManager.vault.authBackend to `cert`\n  ##\n  # vaultClientCert: |-\n\n  ## provide the client key for authenticating with the [TLS](https://www.vaultproject.io/docs/auth/cert.html) backend\n  ## the value will be written to /concourse-vault/client.key\n  ## make sure to also set credentialManager.vault.authBackend to `cert`\n  ##\n  # vaultClientKey: |-\n\n  ## If influxdb metrics are enabled and authentication is required,\n  ## provide a password here to authenticate with the influxdb server configured.\n  ##\n  # influxdbPassword:\n\n  ## SSL certificate used to verify the Syslog server for draining build logs.\n  # syslogCaCert: |-\n",
    "upstream": "https://github.com/helm/charts/tree/0662ec9efe30dda63467bf19ae00217472b1385c/stable/concourse",
    "metadata": {
      "applicationType": "helm",
      "icon": "https://avatars1.githubusercontent.com/u/7809479",
      "license": {
        "assignee": "",
        "createdAt": "0001-01-01T00:00:00Z",
        "expiresAt": "0001-01-01T00:00:00Z",
        "id": "",
        "type": ""
      },
      "sequence": 0,
      "name": "concourse",
      "releaseNotes": "[stable/concourse] Allow namespace creation independently of rbac (#10786)\n\n* Allow namespace creation independently of rbac\n\nAt the moment, when defining `concourse.web.kubernetes.teams`, the helm\nchart will take care of namespace generation. Although this is very\nuseful in most cases, we believe some people may find it problematic.\n\nOur use case, is to create the namespaces ahead of time and fill them\nwith `Pipeline` type resources defining Concourse pipelines. These are\nthen picked by our `pipeline-operator` and continuously applied to\nConcourse for specific teams.\n\nA hacky way around it, would be to set the\n`concourse.web.kubernetes.teams` value to an empty array, and create the\nrole bindings manually. It feels a little like cheating, and a cleaner\nway to accomplish that would be to have a separate flag responsible for\nnamespace creation in the Concourse helm chart.\n\nSigned-off-by: Rafal Proszowski \u003cparoxp@gmail.com\u003e\n\n* Bump patch\n\nSigned-off-by: Rafal Proszowski \u003cparoxp@gmail.com\u003e",
      "version": "3.7.2"
    },
    "contentSHA": "99183db72b179080361aae192a23e926cf0fca14d098c2ce4227d01c843fcec6"
  }
}
